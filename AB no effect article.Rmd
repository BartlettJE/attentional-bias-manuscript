---
title             : "No Meaningful Difference in Attentional Bias Between Daily and Non-Daily Smokers"
shorttitle        : "Attentional bias in Daily and Non-daily Smokers"

author: 
  - name          : "James E Bartlett"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "62 Hillhead Street, University of Glasgow, Glasgow, United Kingdom"
    email         : "james.bartlett@glasgow.ac.uk"
  - name          : "Rebecca Jenks"
    affiliation   : "1"
  - name          : "Nigel Wilson"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "School of Psychological, Social, and Behavioural Sciences, Coventry University"

authornote: |

abstract: |
   Both daily and non-daily smokers find it difficult to quit smoking long-term. One factor associated with addictive behaviour is attentional bias, but previous research in daily and non-daily smokers found inconsistent results and did not report the reliability of their cognitive tasks. Using an online sample, we compared daily (n = 106) and non-daily (n = 60) smokers in their attentional bias towards smoking pictures. Participants completed a visual probe task with two picture presentation times: 200ms and 500ms. In confirmatory analyses, there were no significant effects of interest, and in exploratory analyses, equivalence testing showed the effects were statistically equivalent to zero. The reliability of the visual probe task was poor, meaning it should not be used for repeated testing or investigating individual differences. The results can be interpreted in line with contemporary theories of attentional bias where there are unlikely to be stable trait-like differences between smoking groups. Future research in attentional bias should focus on state-level differences using more reliable measures than the visual probe task.
 
keywords          : "Non-daily smokers, Daily smokers, Visual probe task, Attentional bias, Equivalence testing"
wordcount         : "4854"

bibliography      : ["references.bib", "r-references.bib"]
csl               : apa.csl

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : yes
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---

```{r setup, include = FALSE}
library("papaja")
require(tidyverse)
require(janitor)
require(afex)
require(psych)
require(cowplot)
require(splithalf)
library(TOSTER)
library(pwr)

# Download raincloud plot source file
# Taken from Allen et al. at https://github.com/RainCloudPlots/RainCloudPlots
source("raincloud_plot.R")

# This chunk sources custom functions to help with reporting stats and reduce repetition 

source("reporting_functions.R")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r main data, message=F, warning=F, include=F}
# Download the two datafiles 
# demographics contains information such as age, gender etc. in short form 
full_dat <- read_csv("Data/OSF_demographics.csv")

# visual probe task data contains task data in long form 
dat <- read_csv(file = "Data/OSF_visual_probe_task.csv")

# Use janitor package to clear names to snake case for easier typing 
dat <- clean_names(dat, case = "snake")

# Perform initial screening process 
# focus on trials display and response screen of Gorilla for RT to dot
# Ignore neutral filler trials, incorrect responses, and super fast responses < 200ms 
dat <- dat %>% 
  filter(display == "trials" & screen_name == "response" & trial_type != "neutral" & correct == 1 & reaction_time > 199)

# outlier removal
# 2.5 times the absolute deviation from the median as a threshold (Leys et al. 2013)
# Calculate this for each participant, SOA condition, and trial type 
dat <- dat %>%
  group_by(participant_private_id, soa, trial_type) %>% 
  mutate(median_rt = median(reaction_time),
         MAD_threshold = stats::mad(reaction_time)*2.5) %>% 
  filter(reaction_time > (median_rt - MAD_threshold) & reaction_time < (median_rt + MAD_threshold))

# Calculate how much data (%) present for exclusion criteria later 
trial_n <- dat %>% 
  group_by(participant_private_id) %>% 
  count() %>% 
  mutate(removed = 256 - n,
         removed_perc = (256 - n) / 256 * 100)

# join full data and number of trials for exclusion criteria
full_dat <- right_join(full_dat, trial_n,
                       by = "participant_private_id")

## Apply exclusion criteria

# Note: more specific criteria have to be entered first, or it gets overwritten 
full_dat <- full_dat %>% 
  mutate(included = case_when(smoke_everyday == "Yes" & cigarettes_per_week == "No" ~ 0, # Remove contradictory participants
                              consent_given == 1 & # exclusion criteria from pre-reg
                                age > 17 & age < 61 &
                                device == "computer" & 
                                past_four_weeks == "Yes" & 
                                removed_perc < 50 & # only participants with 50% or more trials
                                technical_issues == "No" ~ 1))

# 3 participants had technical issues with time since last cigarette data, so manually remove 
excluded <- full_dat %>% 
  count(last_cigarette == "Exclude")

# Reduce down to only eligible participants 
full_dat <- full_dat %>% 
  filter(included == 1 & last_cigarette != "Exclude")

# Remove any ineligible participants from task data
dat <- dat %>% 
  filter(participant_private_id %in% full_dat$participant_private_id)

```

# Take-home message

Previous research reported greater attentional bias in daily or non-daily smokers using the visual probe task. We found no meaningful difference using the traditional approach of analysing differences in response times. Our visual probe task also showed poor reliability, meaning response time outcomes from the task should not be used in individual differences research or measuring changes in attentional bias across repeated measurements.  

# Purpose 

Daily and non-daily smokers have different habits and motives but both groups find it difficult to quit smoking long-term. As attentional bias may be associated with addictive behaviour, we used the visual probe task to compare daily and non-daily smokers. We predicted that non-daily smokers would show greater attentional bias towards smoking images than daily smokers. If non-daily smokers showed greater attentional bias, it would help to explain why they find it difficult to quit smoking while showing fewer signs of nicotine dependence.  

\newpage

# Introduction

Historically, smokers have been treated as a single homogeneous group [@shiffman_light_2009], but there are fundamental differences in the smoking habits and motives of daily and non-daily smokers [@shiffman_characteristics_2012; @shiffman_smoking_2012]. 13-36% of smokers are defined as non-daily smokers across Europe and the United States [@bogdanovica_smoking_2011; @kotz_very_2012; @tindle_smoking_2011] and non-daily smoking has typically been the most prevalent pattern in ethnic minority groups [@fagan_light_2009; @tong_nondaily_2006]. Whereas daily smokers cite negative reinforcers such as avoiding nicotine withdrawal as the key motivators, non-daily smokers cite positive reinforcers such as smoking around friends and alcohol [@shiffman_smoking_2012; @shiffman_smoking_2014]. Despite these differences, 77-92% of daily smokers and 74-83% of non-daily smokers relapse within 90 days of a quit attempt [@bogdanovica_smoking_2011; @kotz_very_2012; @tindle_smoking_2011], showing both groups find it difficult to quit smoking long-term. This means it is important to investigate potential factors associated with smoking behaviour.     

One factor is attentional bias, which is the tendency to fixate attention on cues associated with smoking. Attentional bias is the product of a classical conditioning process where smokers develop conditioned responses to substance-related cues through repeated exposure [@field_attentional_2008]. Theoretical models of attentional bias suggest it has a reciprocal relationship with craving, supported by a meta-analysis showing there is a small positive relationship [@field_meta-analytic_2009]. In situations where cigarettes are available, cues associated with smoking grab attention, induce craving, which further drives attentional bias. Updated theories of attentional bias [@field_role_2016] emphasise the role of momentary evaluations of smoking cues, meaning attentional bias and craving fluctuates over time, and describe attempts to extinguish the conditioned response through attentional bias modification. Due to its predicted role in smoking behaviour, studies have investigated whether attentional bias is higher in certain groups or conditions.    

Consistent with theoretical models, smokers consistently show greater attentional bias towards smoking cues than non-smokers [@baschnagel_using_2013; @ehrman_comparing_2002; @kang_individual_2012; @mogg_eye_2003]. However, there are contrasting expectations and findings around how lighter and heavier smokers^[Note, we refer to lighter and heavier smokers here as the studies used different definitions. In our study, we operationalise the groups as daily and non-daily smokers.] differ in attentional bias. One view is lighter smokers should show greater attentional bias than heavier smokers since they rarely show signs of nicotine dependence, so smoking-related cues are required to induce craving and motivate substance use. In support, some studies found lighter smokers exhibit greater attentional bias than heavier smokers [@bradley_attentional_2003; @hogarth_attentional_2003; @mogg_attentional_2005]. Another view is heavier smokers should show greater attentional bias than lighter smokers since the conditioned response to smoking-related cues should be stronger from repeated exposure. There is also evidence for this view as heavier smokers showed greater attentional bias than lighter smokers [@chanon_attentional_2010; @vollstadt-klein_attention_2011; @zack_effects_2001]. Collectively, these studies show smokers consistently display greater attentional bias towards smoking cues than non-smokers, but it is not clear whether lighter or heavier smokers show greater attentional bias. 

To address this inconsistency, the current study focused on comparing attentional bias towards smoking cues in daily and non-daily smokers. Despite most studies using the visual probe task to measure attentional bias, relatively small sample sizes and inconsistent design features complicate making conclusions about the mixed findings. Therefore, we used a much larger sample size than previous studies and manipulated different features of the visual probe task. 

The visual probe task infers attention through differences in response time (RT). Two images are presented and when they disappear, the participant is required to indicate the location of a small probe that replaces one of the images. Faster RTs to particular stimuli reflect selective attention [@field_attentional_2008], but as the location of attention is inferred through differences in RT after the stimuli disappear, the presentation time can be manipulated. Short Stimulus Onset Asynchronies (SOA) of 200ms or less measure involuntary attentional processes [@field_attentional_2008]. Longer SOAs of 500ms or more target voluntary attention as there is enough time to make multiple fixations. Previous research used single SOAs of 500ms [@vollstadt-klein_attention_2011] and 2000ms [@hogarth_attentional_2003; @mogg_attentional_2005]. None of the studies used a very short SOA to measure more involuntary attentional processes. @chanon_attentional_2010 found that in comparison to non-smokers, attentional bias was greater in smokers under a 200ms conditions than a 550ms condition. To investigate the conflict in results between daily and non-daily smokers, this study used two SOAs of 200ms and 500ms. 

A final consideration of our study was to evaluate and report the internal consistency of the visual probe task. There is growing awareness that the reliability of cognitive tasks should be taken seriously [@parsons_psychological_2019; @pennington_raising_2021], but reliability has a different meaning depending on the context. For experimental measures to be reliable, we want to consistently observe effects between groups or conditions, but for correlational measures to be reliable, we want to consistently rank individuals [@hedge_reliability_2018]. This means the attributes of experimental measures may not be compatible with the requirements for reliable correlation research. As researchers often use the visual probe task as a measure in cognitive bias modification procedures, it must be reliable to detect any changes across time. Previous attempts at evaluating the internal consistency of the visual probe task have been disappointing [@schmukle_unreliability_2005; @ataya_internal_2012; @waechter_measuring_2014]. Therefore, we are following recommendations to habitually report the reliability of cognitive tasks [@parsons_psychological_2019], even when it is not the main focus of the study.  

The protocol and hypotheses for this project were pre-registered on the Open Science Framework (OSF; https://osf.io/am9hd/?view_only=3e00300f83e34dc0bddf71408ccc3a12). Given the relevance of smoking cues for non-daily smokers and the results from previously unpublished research, we hypothesised non-daily smokers would show greater attentional bias than daily smokers. There was no *a priori* hypothesis for the effect of SOA condition. This means we expected non-daily smokers to show greater attentional bias than daily smokers, but it was not clear what the difference in magnitude would be under different SOA conditions. 

# Method

## Design

We used a 2 x 2 mixed design with one between-subjects IV of smoking group with two levels: daily and non-daily smokers. Participants responded to the question "Do you usually smoke cigarettes every day?". Non-daily smokers responded "No" and daily smokers responded "Yes". There was one within-subjects IV of the visual probe task SOA which had two levels: 200ms and 500ms. The dependent variable was the attentional bias index (ms) calculated by subtracting the mean RT to smoking trials from the mean RT to non-smoking trials. This means positive values indicate greater attentional bias towards smoking cues. 

## Participants and Sample Size Calculation

We collected data online using Prolific where inclusion criteria consisted of participants should have normal or corrected-normal vision, be between the ages of 18 to 60, and smoke at least one cigarette per week or four cigarettes per month.

We simulated a power analysis to justify the sample size. We set the smallest effect size of interest based on a previously unpublished study [@bartlett_daily_2020] where the mean difference in attentional bias score between smoking groups was 6.13ms (95% CI = [-5.27, 17.53]) for a 200ms SOA and 11.35ms (95% CI = [-4.51, 27.21] for a 500ms SOA. However, we also consulted previous research due to the wide confidence intervals. The smallest known effects for a 200ms SOA was 5ms [@chanon_attentional_2010] and 11ms for a 500ms SOA [@bradley_attentional_2003]. Our smallest effect sizes of interest were 5ms (200ms) and 10ms (500ms), and a conservative standard deviation of 20ms based on @vollstadt-klein_attention_2011. 

These values were used to conduct a simulated power analysis for a 2 x 2 mixed ANOVA using R (code available on the OSF; https://osf.io/am9hd/?view_only=3e00300f83e34dc0bddf71408ccc3a12). We expected non-daily smokers to display greater attentional bias towards smoking images than daily smokers. We set the conditions of the power analysis as non-daily smokers having a 5ms (200ms) and 10ms (500ms) greater mean difference than daily smokers. For each condition, the values were sampled from a normal distribution with a standard deviation of 20ms. The sample size for each smoking group was increased from 10 (N = 20) to 150 (N = 300) in steps of 10, with each step repeating 10,000 times. The final sample size target was 60 per group (N = 120) as we reached 80% power (alpha = .05) between 50 and 60 participants per group.

## Materials 

### Fagerström Test for Cigarette Dependence (FTCD)

```{r FTCD internal consistency, eval=FALSE}

# Eval = FALSE to read from object file

# Number of iterations for bootstrapping
iters <- 1e4 # 10,000

# Select from the 6 FTCD items 
FTCD_reliability <- full_dat[, 16:21]

# Three participants missing cigarette per day, so remove 
FTCD_reliability <- FTCD_reliability[complete.cases(FTCD_reliability), ]

# Save Cronbach's alpha object with bootstrapping 
FTCD.alpha <- psych::alpha(FTCD_reliability, n.iter = iters)

write_rds(FTCD.alpha, file = "Data/FTCD Alpha Object.Rds")
```

```{r read alpha object}

FTCD.alpha <- read_rds("Data/FTCD Alpha Object.Rds")

```

The FTCD [@fagerstrom_determinants_2012; @heatherton_fagerstrom_1991] was used as a self-report measure of nicotine dependence. The Cronbach's alpha estimate (bootstrapped using 10,000 iterations) in this sample was higher than in previous research, $\alpha$ = `r format.alpha(FTCD.alpha)`.

### Visual Probe Task

We used Gorilla [@anwyl-irvine_gorilla_2019] to present the visual probe task online and the task is available on the open materials page to preview or clone (http://gorilla.sc/openmaterials/85021). 

Each trial started with a 250ms central fixation cross before two images were presented horizontally to the left and right. The content and duration of the two images was controlled by two variables: trial type and SOA. Trial type consisted of three conditions (neutral, smoking, or non-smoking) while SOA consisted of two conditions (200ms or 500ms). At picture offset, a small dot appeared in the location vacated by one of the images. The dot remained on the screen until the participant responded either left (Z key) or right (M key). After they responded, the next trial began with the screen containing only the fixation cross. The trial procedure is shown visually in Figure \@ref(fig:task-plot).

The trial type condition was based on 16 image pairs for neutral trials and 16 image pairs for smoking and non-smoking trials. For neutral trials, the dot replaced one of the neutral image pairs. For smoking trials, the dot replaced a smoking image presented next to a matched non-smoking image. For non-smoking trials, the dot replaced a non-smoking image presented next to a smoking image. 

We used 16 image pairs from the International Affective Picture System [@lang_international_2008] for the neutral trials. We developed a series of matching smoking and non-smoking images for the smoking and non-smoking trials [@bartlett_daily_2020]. The list of IAPS images is available on the OSF project and our smoking/non-smoking images are available on the Gorilla open materials page.  

The trial order was randomised with each picture pair presented four times to cover each combination of image (left and right) and dot location (left and right). This combination determined the trial type condition, where a left smoking image, right non-smoking image, and left dot would produce a smoking trial. For each picture pair, this process was repeated twice for each SOA condition, producing 384 trials split into two blocks with 64 trials in each SOA and trial type condition.

(ref:task-plot-caption) Diagram showing the trial procedure of the visual probe task. Each trial started with a fixation cross lasting 250ms. The fixation cross is then flanked by one of the stimulus pairs on the left and right. The stimuli remained on the screen for 200ms or 500ms depending on the SOA condition. The stimuli disappear and one image is replaced with a small dot. Participants had up to 2000ms to respond whether the dot was on the left or right. The next trial started with a new blank fixation cross.  

```{r task-plot, fig.cap="(ref:task-plot-caption)"}

knitr::include_graphics("task_diagram.png")

```

## Procedure 

We provided participants with an information sheet and they provided informed consent by ticking a box. This study was approved by the Faculty of Health and Life Sciences Ethical Approval board. Participants completed a short questionnaire on their demographic information, smoking habits, and the FTCD. The next page contained the visual probe task which began with a set of instructions asking the participant to complete the task in a quiet environment free of distractions. Participants completed 12 practice trials which provided feedback on their responses and overall accuracy. After the task, participants reported whether they experienced any technical issues, whether they used an ineligible device, and if they had completed the study before. Similar to @clifford_is_2014, we asked participants if they had any distractions while they completed the study such as listening to music. Finally, participants read a debriefing sheet before they were redirected to Prolific. If the participants successfully reached the end of the study, they were paid £2.

# Results

## Participant Attrition and Demographics  

```{r demographics, include=F, message=F, warning=F}

# Convert data to numeric - read as character originally 
full_dat$age <- as.numeric(full_dat$age)
full_dat$age_started_smoking <- as.numeric(full_dat$age_started_smoking)
full_dat$cpd <- as.numeric(full_dat$cpd)
full_dat$last_cigarette <- as.numeric(full_dat$last_cigarette)

# Add alternate dependence criteria for exploratory analyses
full_dat <- full_dat %>% 
  mutate(FTCD = case_when(FTCDsum < 3 ~ "Non-dependent",
                          FTCDsum > 2 ~ "Dependent"),
         CPD = case_when(cpd  < 10 ~ "Light", 
                         cpd > 9 ~ "Heavy"))

# Subset data into daily and non-daily smokers for table 
nondaily <- full_dat %>% 
  filter(smoke_everyday == "No")

daily <- full_dat %>% 
  filter(smoke_everyday == "Yes")

# Calculate percentage ethnicities in non-daily smokers 
nondaily_ethnicity <- nondaily %>% 
  count(ethnicity) %>%
  mutate(perc = round(n / nrow(nondaily), 2))

# Isolate percentage white participants and format for simple table entry 
nondaily_white <- paste0(nondaily_ethnicity$perc[4]*100, "%")

# Calculate percentage ethnicities in daily smokers 
daily_ethnicity <- daily %>% 
  count(ethnicity) %>%
  mutate(perc = round(n / nrow(daily), 2))

# Isolate percentage white participants and format for simple table entry 
daily_white <- paste0(daily_ethnicity$perc[5]*100, "%")

# Calculate percentage female participants for non-daily smokers 
perc_nondaily <- round(length(subset(nondaily, nondaily$gender == "Female"))/nrow(nondaily)*100, 2)

# format for simple table entry 
perc_nondaily <- paste0(perc_nondaily, "%")

# Calculate percentage female daily smokers 
perc_daily <- round(length(subset(daily, daily$gender == "Female"))/nrow(daily)*100, 2)

# format for simple table entry 
perc_daily <- paste0(perc_daily, "%")

# Build table using tribble to define each cell for non-daily and daily smokers 
desc_table <- tribble(~"", ~"Non-Daily Smokers", ~"Daily Smokers",
        "Age", mean_sd(nondaily$age), mean_sd(daily$age),
        "% female", perc_nondaily, perc_daily,
        "% white", nondaily_white, daily_white,
        "FTCD", mean_sd(nondaily$FTCDsum), mean_sd(daily$FTCDsum),
        "Cigarettes per day", mean_sd(nondaily$cpd), mean_sd(daily$cpd),
        "Age started to smoke", mean_sd(nondaily$age_started_smoking), mean_sd(daily$age_started_smoking),
        "Time since last cigarette (minutes)*", median_IQR(nondaily$last_cigarette), median_IQR(daily$last_cigarette) 
)
```

```{r smoking figure set up, warning=F, message=F, include=F}
# Create plot grid for FTCD and CPD data in daily and non-daily smokers 

# CPD 
CPD.plot <- full_dat %>% 
  ggplot(aes(x = smoke_everyday, y = as.numeric(cpd), fill = smoke_everyday)) + 
  # Define raincloud plot settings (Allen et al. 2019)
  geom_flat_violin(position = position_nudge(x = .2, y = 0),adjust =2) +
  geom_boxplot(aes(x = smoke_everyday, y = as.numeric(cpd)),
               outlier.shape = NA, alpha = 0.6, width = .1, colour = "BLACK") + 
  geom_point(position = position_jitter(width = .15), size = .25) + 
  xlab("Smoking Group") + 
  scale_x_discrete(labels=c("Non-daily", "Daily")) + 
  ylab("Cigarettes Per Day") + 
  scale_fill_manual(values = c("#1f78b4", "#a6cee3")) + 
  coord_flip() + 
  guides(fill = FALSE) +
  guides(color = FALSE) + 
  theme_cowplot()

# FTCD
FTCD.plot <- full_dat %>% 
  ggplot(aes(x = smoke_everyday, y = FTCDsum, fill = smoke_everyday)) + 
  # Define raincloud plot settings 
  geom_flat_violin(position = position_nudge(x = .2, y = 0),adjust =2) +
  geom_boxplot(aes(x = smoke_everyday, y = FTCDsum),
               outlier.shape = NA, alpha = 0.6, width = .1, colour = "BLACK") + 
  geom_point(position = position_jitter(width = .15), size = .25) + 
  xlab("Smoking Group") + 
  scale_x_discrete(labels=c("Non-daily", "Daily")) + 
  ylab("Total FTCD Score") + 
  scale_fill_manual(values = c("#1f78b4", "#a6cee3")) + 
  scale_y_continuous(breaks = seq(0, 10, 2),
                     limits = c(0, 10)) + 
  coord_flip() + 
  guides(fill = FALSE) +
  guides(color = FALSE) + 
  theme_cowplot()

# Combine each plot into a grid ordered vertically 
smoking_plot <- plot_grid(CPD.plot, FTCD.plot,
          ncol = 1, nrow = 2, labels = c("A", "B"))

# save_plot(plot = smoking_plot,
#           filename = "plots/CPD_FTCD_plot.png",
#           base_height = 7.5,
#           base_width = 7.5, 
#           bg = "white")
```

218 people accessed the study and 205 completed the experiment and received payment. The final sample was 166 after applying exclusion criteria: 60 non-daily and 106 daily smokers. Participants were excluded for having fewer than 50% of the possible trials (n = 4), experiencing technical issues (n = 16), reporting to smoke every day but not every week (n = 3), and not smoking in the past four weeks (n = 19). The total number equals 42 as some participants met more than one criterion.   

Table \@ref(tab:demographics-table) displays the demographic information. Daily smokers smoked more cigarettes per day and had a higher FTCD score. Non-daily smokers exemplified infrequent smoking as the median time since their last cigarette was 48 hours, while it was only one hour for daily smokers. Figure \@ref(fig:smoking-plot) shows the distribution of FTCD scores and cigarettes per day.

```{r demographics-table}
# Use papaja helper function to create a pretty table 
apa_table(desc_table,
          caption = "Mean (SD) values for participant characteristics and scale scores.",
          note = "*Due to large skew, these values represent the median and IQR.")
```

(ref:smoking-plot-caption) Two different measures of nicotine dependence: (A) number of cigarettes per day and (B) FTCD score. The data are presented as raincloud plots [@allen_raincloud_2019]. The top element for each group represents the distribution of scores through the density. The bottom element presents the individual data points with a superimposed boxplot.

```{r smoking-plot, fig.cap="(ref:smoking-plot-caption)"}
# Display smoking grid plot. Caption comes from statement previously 
smoking_plot
```

## Data Processing 

```{r missing data}
# Calculate how much missing data to enter into text  
trials_median <- median(full_dat$removed)

trials_range <- range(full_dat$removed)

# What % of trials is remaining? 
trials_removed <- nrow(dat) / (256 * length(unique(dat$participant_private_id))) * 100

trials_removed <- round(100 - trials_removed, 2)
```

The R code is available on the OSF (https://osf.io/am9hd/?view_only=3e00300f83e34dc0bddf71408ccc3a12). We removed incorrect responses in addition to responses faster than 200ms as they represent preemptive responses. We considered outliers as any response outside 2.5 times the median absolute deviation for each participant, SOA, and trial condition (Leys et al. 2013). This meant we removed `r trials_removed`% of the total possible trials, with the median number of excluded trials for each participant being `r trials_median` (range `r trials_range[1]` - `r trials_range[2]`). 

For the confirmatory analyses, we focused on smoking/non-smoking image pairs and excluded the neutral pairs. Originally, we planned on conducting exploratory analyses to create orienting and disengagement indices [@salemink_selective_2007] by subtracting the mean RT to neutral trials from smoking trials (orienting) or non-smoking trials (disengagement), but a coding error meant we did not have matching numbers of neutral trials in the 200ms and 500ms SOA conditions. Therefore, we focused on our confirmatory analyses and excluded neutral trials.

After removing outliers, we calculated the mean RT to probes that replaced non-smoking images and the mean RT to probes that replaced smoking images. We then calculated the difference between these two values as our attentional bias index (non-smoking - smoking), where positive values mean faster average responses to smoking images. For each participant, this produced two values: one for the attentional bias index using a 200ms SOA and one using a 500ms SOA.  

## Confirmatory Analyses: Attentional Bias Towards Smoking Cues 

```{r mean differences}
# Calculate mean RT for each condition
ab_analysis <- dat %>% 
  group_by(participant_private_id, trial_type, soa) %>% 
  summarise(mean_rt = mean(reaction_time))

# Spread smoking and neutral trials to calculate AB index
ab_analysis <- ab_analysis %>% 
  spread(key = trial_type, value = mean_rt) %>% 
  mutate(ab_index = nonsmoking - smoking)

# Isolate key variables from demographs to join with AB data
smoking_dat <- full_dat %>% 
  select(participant_private_id, smoke_everyday, CPD, FTCD, last_cigarette)

# Add daily / non-daily smoking info 
ab_analysis <- right_join(ab_analysis, smoking_dat,
                       by = "participant_private_id")

# Calculate mean and SD for AB index
ab_descriptives <- ab_analysis %>% 
  group_by(smoke_everyday, soa) %>% 
  summarise(mean_bias = round(mean(ab_index), 2),
            sd_bias = round(sd(ab_index), 2))

```

The mean (*SD*) attentional bias index in the 200ms SOA condition was `r  ab_descriptives$mean_bias[3]`ms (`r ab_descriptives$sd_bias[3]`) for daily smokers and `r  ab_descriptives$mean_bias[1]`ms (`r ab_descriptives$sd_bias[1]`) for non-daily smokers. In the 500ms SOA condition, the mean bias index was `r  ab_descriptives$mean_bias[4]`ms (`r ab_descriptives$sd_bias[4]`) for daily smokers and `r  ab_descriptives$mean_bias[2]`ms (`r ab_descriptives$sd_bias[2]`) for non-daily smokers. This was in the opposite direction to our hypotheses as we expected non-daily smokers to display greater attentional bias towards smoking images than daily smokers. The results are displayed in Figure \@ref(fig:interaction-plot).

```{r ANOVA and interaction plot, warning=F, include=F, message=F}
# Relabel to daily and non-daily smokers to look better 
ab_analysis$smoke_everyday[ab_analysis$smoke_everyday == "Yes"] <- "Daily" 
ab_analysis$smoke_everyday[ab_analysis$smoke_everyday == "No"] <- "Non-daily" 

# Calculate 2x2 ANOVA using afex 
anov <- aov_ez(id = "participant_private_id",
       dv = "ab_index", 
       between = "smoke_everyday",
       within = c("soa"),
       data = ab_analysis)

# Define interaction plot based on anova object 
interaction.plot <- afex_plot(anov, 
          x = "soa", 
          trace = "smoke_everyday",
          error_ci = T, # Show 95% CI 
          legend_title = "Smoking Group",
          point_arg = list(size = 2),
          error_arg = list(size = 1, width = 0.1),
          line_arg = list(size = 1),
          mapping = c("color", "shape", "fill")) + # ensure link and error bars coloured  
  xlab("SOA") + 
  ylab("Attentional Bias Index (ms)") + 
  scale_x_discrete(labels = c("200ms", "500ms")) + 
  geom_hline(yintercept = 0, linetype = 2) + # Display 0 AB index for reference 
  scale_y_continuous(breaks = seq(-100, 100, 25),
                     limits = c(-100, 100)) + 
  scale_colour_manual(values = c("#a6cee3", "#1f78b4")) + 
  theme_cowplot()

# save_plot(plot = interaction.plot,
#           filename = "plots/AB_interaction.png",
#           base_height = 7.5,
#           base_width = 10,
#           bg = "white")
```

(ref:interaction-plot-caption) Interaction plot showing the mean attentional bias index for daily and non-daily smokers by SOA condition. The error bars represent the 95% CI around the mean. Positive values indicate greater attentional bias towards smoking cues. The grey points show the individual scores per condition.

```{r interaction-plot, fig.cap="(ref:interaction-plot-caption)"}
# Display interaction plot. Caption defined in previous statement. 
interaction.plot

```

We used a 2x2 mixed ANOVA with SOA as a within-subjects IV and smoking group as a between-subjects IV. The mean attentional bias index was the DV. There was not a significant effect of SOA (`r format.afex_anova(anov, 2)`) or smoking group (`r format.afex_anova(anov, 1)`). There was also no significant interaction between the two factors, `r format.afex_anova(anov, 3)`. This did not support our prediction that non-daily smokers would show greater attentional bias towards smoking images than daily smokers.  

## Exploratory Analyses: No Meaningful Difference in Attentional Bias 

```{r equivalence testing results, warning=F, include=F, message=F}
# Isolate mean and SD RT for smoking group and SOA condition 
mean_sd <- ab_analysis %>% 
  group_by(smoke_everyday, soa) %>% 
  summarise(mean_RT = mean(ab_index),
            sd_RT = sd(ab_index))

# Convert to data frame frame from table as formatting was messing up the TOST function 
mean_sd <- as.data.frame(mean_sd)

# Comparing daily and non-daily smokers on 200ms SOA
# boundaries set to d ± .41 based on small telescope approach (Lakens et al. 2018)
# Vollstaedt-Klein et al. 33% power to detect d = .41. 
SOA200 <- TOSTtwo(m1 = mean_sd[1, 3], m2 = mean_sd[3, 3], 
                  sd1 = mean_sd[1, 4], sd2 = mean_sd[3, 4], 
                  n1 = 106, n2 = 60, 
                  low_eqbound_d = -0.41, high_eqbound_d = 0.41)

# Comparing daily and non-daily smokers on 500ms SOA
# Same boundaries as above 
SOA500 <- TOSTtwo(m1 = mean_sd[2, 3], m2 = mean_sd[4, 3], 
                  sd1 = mean_sd[2, 4], sd2 = mean_sd[4, 4], 
                  n1 = 106, n2 = 60, 
                  low_eqbound_d = -0.41, high_eqbound_d = 0.41)

# Populate tibble for key information needed for plotting 
# Isolate mean difference with 90% and 95% CI for each SOA condition 
equivalence_dat <-
  tribble(
    ~ condition,
    ~ mean_diff,
    ~ LL_TOST,
    ~ UL_TOST,
    ~ LL_TTEST,
    ~ UL_TTEST,
    "200ms",
    SOA200$diff,
    SOA200$LL_CI_TOST,
    SOA200$UL_CI_TOST,
    SOA200$LL_CI_TTEST,
    SOA200$UL_CI_TTEST,
    "500ms",
    SOA500$diff,
    SOA500$LL_CI_TOST,
    SOA500$UL_CI_TOST,
    SOA500$LL_CI_TTEST,
    SOA500$UL_CI_TTEST
  )

# Create manual TOST plot to demonstrate the mean difference + 90% / 95% CI 
TOST_plot <- equivalence_dat %>% 
  ggplot(aes(x = condition, y = mean_diff)) + 
  geom_point(size = 5, shape = 3) + # Show mean difference with horizontal line 
  # Create two error bars for 90% and 95% CI - differentiate with thicker 90% line
  geom_errorbar(aes(ymin = LL_TOST, ymax = UL_TOST), width = 0, size = 2) + 
  geom_errorbar(aes(ymin = LL_TTEST, ymax = UL_TTEST), width = 0) + 
  # Demonstrate effect size boundary in raw mean difference units 
  geom_hline(yintercept = -8.42, linetype = 2) +
  geom_hline(yintercept = 8.42, linetype = 2) +
  # Reference point at 0 mean difference 
  geom_hline(yintercept = 0, linetype = 5) +
  scale_y_continuous(breaks = seq(-10, 10, 2),
                     limits = c(-10, 10)) + 
  ylab("Mean Difference in AB Index (ms)") + 
  xlab("SOA Condition") + 
  theme_cowplot() + 
  # flip on it's side to visualise easier 
  coord_flip()

 # save_plot(plot = TOST_plot,
 #           filename = "plots/TOST_plot.png",
 #           base_height = 7.5,
 #           base_width = 10,
 #           bg = "white")
  
```

To demonstrate there was no meaningful difference between daily and non-daily smokers, we performed equivalence testing on the two comparisons of interest: the difference between daily and non-daily smokers at each SOA condition. You cannot directly provide evidence in favour of the null hypothesis using traditional null hypothesis significance testing. Equivalence testing applies two one-sided tests to user-defined boundaries representing effects you consider too small to be practically or theoretically meaningful [@lakens_equivalence_2018]. If both tests are statistically significant, you can conclude your observed effect size is statistically equivalent to zero based on your boundaries. 

There are different approaches to setting the boundaries for your smallest effect size of interest. We used Cohen's d = ±0.41 based on the small telescopes method [@lakens_equivalence_2018]. This is where you use the effect size that the largest previous study had 33% power to detect (in our case, @vollstadt-klein_attention_2011 with two groups of 25 and 26 participants). The small telescopes method is appropriate when previous research did not define their smallest effect size of interest, so it represents the effect size large enough to be detectable in the original study [@simonsohn_small_2015]. Considering alternative choices for the effect size boundaries, our conclusions below hold when we use the larger effect size from our power analysis (10ms) but not when we use the smaller effect size (5ms). Given we are arguing differences in attentional bias in daily and non-daily smokers may be smaller than reported in previous research, we focus on the results using the small telescopes method.      

For the 200ms SOA condition, the two one-sided test procedure was significant, demonstrating that the difference in attentional bias towards smoking images between daily and non-daily smokers was statistically equivalent to zero, `r format.TOST(SOA200)`. Similarly, the 500ms SOA condition was statistically equivalent to zero, `r format.TOST(SOA500)`. The equivalence testing procedure is presented in Figure \@ref(fig:TOST-plot), showing that the 90% confidence interval around the mean difference crosses zero, but does not cross the effect size boundaries of d = ±.41 (expressed here in raw units). 

(ref:TOST-plot-caption) The thin vertical lines show the mean difference in attentional bias index between daily and non-daily smokers in each SOA condition. The thick horizontal black lines represent the 90% confidence interval for the two one-sided test procedure. The thin horizontal black lines represent the 95% confidence interval. The dashed vertical lines represent the equivalence boundaries in raw scores. 

```{r TOST-plot, fig.cap="(ref:TOST-plot-caption)"}
# Display TOST plot - caption defined in previous statement 
TOST_plot

```

## Exploratory Analyses: Including trial type as an additional IV

In our preregistration protocol, we focused on the attentional bias index as our outcome for confirmatory analyses, calculating it from the difference between smoking and neutral trials. While there were no meaningful differences between smoking groups, both peer-reviewers questioned whether participants first showed an attentional bias effect towards smoking images. Therefore, we performed exploratory analyses where we included trial type as an additional within-subjects IV instead of calculating the difference in RT between each condition. 

```{r trial type analyses}

trial_analysis <- ab_analysis %>% 
  pivot_longer(cols = c(nonsmoking, smoking), names_to = "condition", values_to = "RT") %>% 
  mutate(AB = case_when(ab_index < 0 ~ 0, # Do participants show positive or negative AB effect? 
                        ab_index > 0 ~ 1))

# Average AB effect for each group / SOA condition
persons_effect <- trial_analysis %>%
  group_by(smoke_everyday, soa) %>%
  summarise(perc_ab = round(mean(AB)*100, 2))

# Calculate 2x2x2 ANOVA using afex 
anov_trial <- aov_ez(id = "participant_private_id",
       dv = "RT", 
       between = "smoke_everyday",
       within = c("soa", "condition"),
       data = trial_analysis)

# Relabel for plotting
trial_analysis$smoke_everyday[trial_analysis$smoke_everyday == "Daily"] <- "Daily Smokers" 
trial_analysis$smoke_everyday[trial_analysis$smoke_everyday == "Non-daily"] <- "Non-Daily Smokers" 

# Persons as effect sizes plot
person_effects_plot <- trial_analysis %>% 
  mutate(condition = factor(condition, labels = c("Non-Smoking", "Smoking")),
         soa = factor(soa, labels = c("200ms SOA", "500ms SOA"))) %>% 
  ggplot(aes(x = condition, y = RT, group = participant_private_id, colour = as.factor(AB))) + 
  geom_point(alpha = 0.8) + 
  geom_line(size = 0.8, alpha = 0.8) + 
  facet_grid(smoke_everyday~soa) + 
  theme_cowplot() + 
  scale_colour_viridis_d(option="plasma", 
                       begin=0.1, 
                       end=0.8, 
                       name = "Attentional Bias Effect",
                       labels = c("Faster Non-Smoking", "Faster Smoking")) + 
  labs(x = "Trial Type", y = "Response Time (ms)")

 # save_plot(plot = person_effects_plot,
 #           filename = "plots/persons_effects_plot.png",
 #           base_height = 7.5,
 #           base_width = 10,
 #           bg = "white")
```

We used a 2x2x2 mixed ANOVA using RT as our DV, trial type and SOA as within-subject IVs, and smoking group as a between-subjects IV. The only significant effect was SOA (`r format.afex_anova(anov_trial, 2)`), which in isolation is not theoretically meaningful to us. None of the other effects were statistically significant. 

Although there were no significant effects including trial type, we quantified whether participants showed an attentional bias effect towards smoking images using the persons as effect sizes approach [@grice_persons_2020]. Instead of a blanket mean difference between groups or conditions, you can quantify how many participants behaved consistent with theoretical predictions. In this context, we can ask how many participants showed faster RTs to smoking trials compared to non-smoking trials. 

For each participant, we coded whether the difference in RT was negative (faster responses to non-smoking images) or positive (faster responses to smoking images), then calculated the percentage showing a positive effect for each smoking group and SOA condition. Participants rarely deviated from 50% showing the expected faster responses to smoking images. `r persons_effect[1, 3]`% of daily smokers in the 200ms and `r persons_effect[2, 3]`% in the 500ms SOA condition showed faster responses to smoking images. `r persons_effect[3, 3]`% of non-daily smokers in the 200ms SOA condition showed faster responses to smoking images, while `r persons_effect[4, 3]`% responded faster to smoking images in the 500ms SOA condition, suggesting more participants responded faster to non-smoking images. We visualised these results in Figure \@ref(fig:trial-plot) where each line represents a participant and the colour shows whether they responded faster to smoking or non-smoking images for each SOA condition and smoking group. Collectively, these exploratory analyses suggest participants did not display the predicted attentional bias effect towards smoking images.  

(ref:trial-plot-caption) A dot plot visualising whether each participant showed the predicted attentional bias effect towards smoking images. Each line represents one participant where their average RT to non-smoking and smoking images is connected. Positive colour-coded slopes show participants who responded faster to non-smoking images while negative colour-coded slopes show participants who responded faster to smoking images. Each panel represents the combination of smoking group and SOA condition.    

```{r trial-plot, fig.cap="(ref:trial-plot-caption)"}

person_effects_plot

```

## Exploratory Analyses: Visual Probe Task Reliability

```{r cronbachs alpha, message=F, warning=F, results="hide", eval=FALSE}
# Eval set to false to save time - load objects below...

# Calculate Cronbach's alpha for each SOA condition in visual probe task 
# Follow procedure of Christiansen et al. (2015) to calculate AB index for each picture pair 
# Produces 16 AB indexes for each SOA condition. Treat these as "items" to calculate internal consistency 

# Begin by repeating processing for visual probe task data 
rel.dat <- read_csv(file = "Data/OSF_visual_probe_task.csv")

rel.dat <- clean_names(rel.dat, case = "snake")

# Perform initial screening process 
rel.dat <- rel.dat %>% 
  filter(display == "trials" & screen_name == "response" & trial_type != "neutral" & correct == 1 & reaction_time > 199)

# outlier removal
# 2.5 times the absolute deviation from the median as a threshold
rel.dat <- rel.dat %>%
  group_by(participant_private_id, soa, trial_type, stimulus_no) %>% 
  mutate(median_rt = median(reaction_time),
         MAD_threshold = stats::mad(reaction_time)*2.5) %>% 
  filter(reaction_time > (median_rt - MAD_threshold) & reaction_time < (median_rt + MAD_threshold))

# Include stimulus number as a factor to get a mean RT per participant, SOA, trial, and stimulus (due to images being repeated)
rel.dat <- rel.dat %>% 
  group_by(participant_private_id, soa, trial_type, stimulus_no) %>%
  filter(participant_private_id %in% full_dat$participant_private_id) %>% # Remove ineligible participants 
  summarise(mean_rt = mean(reaction_time)) %>% 
  spread(key = trial_type, value = mean_rt) %>% 
  mutate(AB_index = nonsmoking - smoking)

# Convert stimulus number to factor 
rel.dat$stimulus_no <- as.factor(rel.dat$stimulus_no)

# Start with 200ms SOA condition 

rel.analysis <- rel.dat %>% 
  filter(soa == 200) %>% 
  select(stimulus_no, AB_index)

# get rid of SOA column to stop it messing up 
rel.analysis <- rel.analysis[c(1, 3, 4)]

# Convert to wide format for one AB index per stimulus number spread across columns 
rel.analysis <- rel.analysis %>% 
  spread(key = stimulus_no, value = AB_index)

# Calculate Cronbach's alpha with 10,000 bootstraps 
alpha.200 <- psych::alpha(rel.analysis[2:17],
             n.iter = 1e4)

# Repeat for 500ms SOA condition 
rel.analysis <- rel.dat %>% 
  filter(soa == 500) %>% 
  select(stimulus_no, AB_index)

# get rid of SOA column to stop it messing up 
rel.analysis <- rel.analysis[c(1, 3, 4)]

# Convert to wide format 
rel.analysis <- rel.analysis %>% 
  spread(key = stimulus_no, value = AB_index)

# Cronbach's alpha with 10,000 bootstraps 
alpha.500 <- psych::alpha(rel.analysis[2:17],
             n.iter = 1e4)

write_rds(alpha.200, "Data/Object Alpha 200ms SOA.Rds")
write_rds(alpha.500, "Data/Object Alpha 500ms SOA.Rds")

```

```{r load alpha objects}

# Save knitting time by reading .RDS object 

alpha.200 <- read_rds("Data/Object Alpha 200ms SOA.Rds")

alpha.500 <- read_rds("Data/Object Alpha 500ms SOA.Rds")

```

We calculated Cronbach's alpha for the attentional bias index across the 16 stimulus pairs which was poor for both the 200ms ($\alpha$ = `r format.alpha(alpha.200)`) and 500ms ($\alpha$ = `r format.alpha(alpha.500)`) SOA conditions. 

```{r split half reliability, message=F, warning=F, results="hide", eval=FALSE}

# Eval = false to speed things up and load from .RDS file 

# Parsons et al. (2019) criticised alpha for cognitive tasks and present split half reliability 
# Calculate permutation split half reliability with 5000 iterations 
# No special processing necessary as function takes long form data
difference <- splithalf(data = dat,
                        outcome = "RT",
                        score = "difference", # Calculate mean difference in RT between conditions
                        conditionlist = c("200", "500"),
                        halftype = "random",
                        permutations = 5000,
                        var.RT = "reaction_time",
                        var.condition = "soa",
                        var.participant = "participant_private_id",
                        #var.trialnum = "trial_number",
                        var.compare = "trial_type",
                        compare1 = "nonsmoking",
                        compare2 = "smoking",
                        average = "mean")

write_rds(difference, "Data/splifhalf object.Rds")

```

```{r load difference}

difference <- read_rds("Data/splifhalf object.Rds")

```


We reported internal consistency estimates for comparison with previous studies, but they assume the items or trials are presented in the same order [@parsons_psychological_2019]. As cognitive tasks randomise trials, internal consistency may not be the best approach. An alternative is a permutation approach to calculating split-half reliability [@R-splithalf]. This randomly splits the data set into two halves many times and calculates the average correlation between each half. Using 5000 iterations, poor reliability was also reflected in the split-half estimate (corrected using the Spearman-Brown formula) for the 200ms (`r format.splithalf(difference, "200")[1]`) and 500ms (`r format.splithalf(difference, "500")[2]`) SOA conditions. 

# Discussion

We hypothesised that non-daily smokers would display greater attentional bias towards smoking cues than daily smokers. Some studies found that non-daily smokers exhibited greater attentional bias [@bradley_attentional_2003; @hogarth_attentional_2003; @mogg_attentional_2005], whereas others found that daily smokers displayed greater attentional bias [@chanon_attentional_2010; @vollstadt-klein_attention_2011; @zack_effects_2001]. Using traditional methods that calculate an attentional bias index from average differences in RT, there were no significant differences, and using equivalence testing showed there was no meaningful difference in attentional bias in daily and non-daily smokers.

```{r sensitivity power}

vollstaedt_sensitivity <- round(
  pwr.t2n.test(n1 = 25, # 166 participants in total
             n2 = 26, 
             power = 0.8,
             sig.level = .05)$d, # Isolate the effect size for sensitivity
  2)

d_power <- round(
  pwr.t2n.test(n1 = 60, # 166 participants in total
                n2 = 106, 
             d = 0.8,
             sig.level = .05)$power, # Isolate the effect size for sensitivity
  3)*100

study_sensitivity <- round(
  pwr.t2n.test(n1 = 60, # 166 participants in total
             n2 = 106, 
             power = 0.8,
             sig.level = .05)$d, # Isolate the effect size for sensitivity
  2)

```

We may have found null results as previous research could have problems with inflated effect sizes due to low statistical power. The previous largest sample was 51 smokers in @vollstadt-klein_attention_2011. Splitting these into 25 and 26 participants, a sensitivity power analysis indicates that this sample size would be sensitive to detect effect sizes of Cohen’s d = `r vollstaedt_sensitivity` (alpha = .05, beta = .20). Incidentally, @schafer_meaningfulness_2019 showed that the median Cohen's d in a random selection of 684 non-pre-registered articles was 0.80. In the long-run, our study would have `r d_power`% power to detect an effect size of 0.80. Therefore, it is unlikely the effect size between daily and non-daily smokers is this large, or we would have had enough power to detect it. Our study had the largest known sample size to investigate attentional bias with 60 non-daily smokers and 106 daily smokers. A sensitivity power analysis shows that this was sensitive to detect effect sizes of Cohen’s d = `r study_sensitivity`. Our study was sensitive to detect an effect size of almost half the size of @vollstadt-klein_attention_2011. Our results were statistically equivalent to zero, meaning there may not be a meaningful difference in attentional bias between smoking groups, at least in its current implementation where the effect is assumed to represent stable trait-like group differences.

Contemporary theories suggest attentional bias may not be a trait-like phenomenon that can produce stable differences between groups. @field_role_2016 suggested that attentional bias varies depending on how substance cues are being evaluated. The theory suggests that rather than being a stable trait between groups, it fluctuates with the incentive value of a cue which makes within-group differences more important. @begh_association_2016 found that laboratory measures like the visual probe task did not predict smoking behaviour in the real-world. However, ecological momentary assessment of craving and awareness of smoking cues did predict smoking behaviour. Therefore, the null results in our study may be a product of the fluctuating nature of attentional bias [@field_role_2016]. In smaller samples, attentional bias could fluctuate one way or the other, but in larger samples like our study, the differences could cancel out and converge to a mean difference around zero. Therefore, future research may benefit from investigating which factors affect the momentary evaluation of substance cues and the subsequent expression of attentional bias.

Using the visual probe task to measure factors that affect the momentary evaluation of substance cues may be problematic though. There are vocal critics of the task due to its questionable level of internal consistency [@ataya_internal_2012; @schmukle_unreliability_2005; @waechter_measuring_2014]. Our study also had suboptimal levels of internal consistency and split-half reliability. Researchers rarely report the reliability of cognitive tasks unless it is the main focus of the article [@parsons_psychological_2019], which means it is difficult to assess how reliable the tasks were in previous smoking research. Experimental measures are designed to produce reliable differences between groups or condition, not consistently rank individuals [@hedge_reliability_2018]. This means if researchers plan to use the visual probe task across multiple measurements - such as in cognitive bias modification or the evaluation of substance cues - then its poor reliability is problematic. Future research should use eye-tracking as a direct measure of attentional bias as it produces larger effect sizes [@field_meta-analytic_2009], has higher internal consistency [@price_empirical_2015], and higher criterion validity [@soleymani_free-viewing_2020].

## Limitations 

Our sample may have been more diverse than typical undergraduates in age and education, but it still contained predominantly white participants. Non-daily smoking is more prevalent in ethnic minority groups [@fagan_light_2009; @levy_natural_2009] and the health implications of smoking disproportionately affect non-white smokers [@st.helen_black_2019]. Therefore, future research would benefit from recruiting a larger proportion of non-white smokers for the results to generalise beyond mostly white smokers.

The online nature of the study meant participants’ smoking levels could not be verified objectively using measures like Carbon Monoxide [@wray_comparative_2016], but @ramo_reliability_2011 demonstrated that smoking-related information collected online has good reliability and validity. Relatedly, as participants completed the study online, there was no control over their smoking behaviour before and during the study. This lead to idiosyncrasies as some smokers reported to smoke while they were completing the study. Although this may represent a more naturalistic environment for the smokers, our study had less control over smokers' deprivation levels.

## Conclusion 

The purpose of our study was investigate the conflict in attentional bias results between daily and non-daily smokers. We expected non-daily smokers to show greater attentional bias towards smoking images than daily smokers. Greater attentional bias in non-daily smokers would have helped to explain why they find it difficult to quit smoking while showing fewer signs of nicotine dependence. However, there were no significant effects, and using equivalence testing, we found that there was no meaningful difference in attentional bias between daily and non-daily smokers. The results can be interpreted in line with contemporary theories of attentional bias where there may not be stable trait-level differences between smoking groups in attentional bias. Future research should focus on investigating how attentional bias fluctuates over time using more reliable measures than the visual probe task. 
\newpage

# Disclosures

## CRediT Contributions

Conceptualization (JEB, RJ, NW); Methodology (JEB, RJ, NW); Formal analysis (JEB); Investigation (JEB); Data curation (JEB); Writing - original draft (JEB); Writing - Review & editing (JEB); Supervision (RJ, NW).

## Data, code, and materials

The data and code to reproduce these analyses are available on the OSF (https://osf.io/am9hd/?view_only=3e00300f83e34dc0bddf71408ccc3a12). The OSF project contains all necessary files to reproduce the analyses and figures. The visual probe task was created in Gorilla and the task can be found using the open materials page (http://gorilla.sc/openmaterials/85021)

## R Package Acknowledgements
```{r r packages}
# Use papaja function to report R and package citations 
# Manually removed some functions within tidyverse that were not used in the analyses 
my_citations <- cite_r(file = "r-references.bib", 
                       pkgs = c("forcats", "lme4", "Matrix", "purrr", "tidyverse"), 
                       withhold = TRUE)
```

The results were created using `r my_citations`. 

\newpage

# References
```{r create_r-references}
# Create bib files for loaded packages

# Will be cited in my_citations above and formatted into bibliography below 
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
